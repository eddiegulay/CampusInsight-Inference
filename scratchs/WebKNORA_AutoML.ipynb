{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import joblib\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "dataset = pd.read_csv(\"April26_Dataset_17172_13_Argumented.csv\")\n",
        "\n",
        "# Separate features and target variable\n",
        "X = dataset.drop('dropout', axis=1)\n",
        "y = dataset['dropout']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# List of classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=0),\n",
        "    'Logistic Regression': LogisticRegression(solver='liblinear'),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Gaussian Naive Bayes': GaussianNB(),\n",
        "    'Multilayer Perceptron': MLPClassifier(),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
        "    'AdaBoost': AdaBoostClassifier()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "location_name [0 1]\n",
            "home_language [2 0 1 3]\n",
            "hh_occupation [0 5 2 3 1 4 6]\n",
            "hh_edu [1 0 3 2]\n",
            "hh_size [ 7  8  5 11 10  6 17  2 15  4  9  1  3 12 14 18 16 13 29 30 20 19 78 34\n",
            " 25 24 21 28 22 23 31 26 35 73]\n",
            "school_distanceKm [  2   0   1   3   6   4  30   5  15  45   7  27   8  20  10   9  12  25\n",
            "  11  14 100  60]\n",
            "age [11 12 13 14 15 16]\n",
            "gender [2 1]\n",
            "mothers_edu [1 2 3 0]\n",
            "grade [11  9 10 12]\n",
            "meansToSchool [0 1 2 3]\n",
            "hh_children [ 7  6  4  3  8  5 17 13  2  1  9 10 11 14 16 12 18 15]\n"
          ]
        }
      ],
      "source": [
        "for col in X.columns:\n",
        "    print(col, X[col].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest...\n",
            "Random Forest trained and saved as random_forest_model.joblib\n",
            "\n",
            "Training Logistic Regression...\n",
            "Logistic Regression trained and saved as logistic_regression_model.joblib\n",
            "\n",
            "Training K-Nearest Neighbors...\n",
            "K-Nearest Neighbors trained and saved as k-nearest_neighbors_model.joblib\n",
            "\n",
            "Training Decision Tree...\n",
            "Decision Tree trained and saved as decision_tree_model.joblib\n",
            "\n",
            "Training Gaussian Naive Bayes...\n",
            "Gaussian Naive Bayes trained and saved as gaussian_naive_bayes_model.joblib\n",
            "\n",
            "Training Multilayer Perceptron...\n",
            "Multilayer Perceptron trained and saved as multilayer_perceptron_model.joblib\n",
            "\n",
            "Training Support Vector Machine...\n",
            "Support Vector Machine trained and saved as support_vector_machine_model.joblib\n",
            "\n",
            "Training Linear Discriminant Analysis...\n",
            "Linear Discriminant Analysis trained and saved as linear_discriminant_analysis_model.joblib\n",
            "\n",
            "Training AdaBoost...\n",
            "AdaBoost trained and saved as adaboost_model.joblib\n",
            "\n",
            "All models trained and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Train and save each model\n",
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"Training {clf_name}...\")\n",
        "    clf.fit(x_train, y_train)\n",
        "\n",
        "    # Save the trained model using joblib\n",
        "    model_filename = f\"{clf_name.replace(' ', '_').lower()}_model.joblib\"\n",
        "    joblib.dump(clf, model_filename)\n",
        "    print(f\"{clf_name} trained and saved as {model_filename}\\n\")\n",
        "\n",
        "print(\"All models trained and saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "def load_models():\n",
        "    \"\"\"\n",
        "    Load all the saved models.\n",
        "    Returns a dictionary containing model names as keys and the corresponding loaded model as values.\n",
        "    \"\"\"\n",
        "    models = {}\n",
        "    model_files = [\n",
        "        \"random_forest_model.joblib\",\n",
        "        \"logistic_regression_model.joblib\",\n",
        "        \"k-nearest_neighbors_model.joblib\",\n",
        "        \"decision_tree_model.joblib\",\n",
        "        \"gaussian_naive_bayes_model.joblib\",\n",
        "        \"multilayer_perceptron_model.joblib\",\n",
        "        \"support_vector_machine_model.joblib\",\n",
        "        \"linear_discriminant_analysis_model.joblib\",\n",
        "        \"adaboost_model.joblib\"\n",
        "    ]\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_name = model_file.split('_model')[0].title().replace('_', ' ')\n",
        "        model = joblib.load(model_file)\n",
        "        models[model_name] = model\n",
        "\n",
        "    return models\n",
        "\n",
        "def make_inference(input_data):\n",
        "    \"\"\"\n",
        "    Make predictions using all loaded models.\n",
        "    :param input_data: Pandas DataFrame containing input data for inference.\n",
        "    :return: Dictionary containing model names as keys and corresponding predictions as values.\n",
        "    \"\"\"\n",
        "    models = load_models()\n",
        "    predictions = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        # Assuming 'input_data' is a DataFrame with the same columns as the training data\n",
        "        # Adjust the input_data accordingly based on your specific needs\n",
        "        model_predictions = model.predict(input_data)\n",
        "        predictions[model_name] = model_predictions\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input_data sample from dataset\n",
        "input_data = dataset.drop('dropout', axis=1).iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions from Random Forest:\n",
            "[1]\n",
            "Predictions from Logistic Regression:\n",
            "[1]\n",
            "Predictions from K-Nearest Neighbors:\n",
            "[1]\n",
            "Predictions from Decision Tree:\n",
            "[1]\n",
            "Predictions from Gaussian Naive Bayes:\n",
            "[1]\n",
            "Predictions from Multilayer Perceptron:\n",
            "[1]\n",
            "Predictions from Support Vector Machine:\n",
            "[1]\n",
            "Predictions from Linear Discriminant Analysis:\n",
            "[1]\n",
            "Predictions from Adaboost:\n",
            "[1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Make predictions using all models\n",
        "all_predictions = make_inference([input_data])\n",
        "\n",
        "# Print or use the predictions as needed\n",
        "for model_name, model_predictions in all_predictions.items():\n",
        "    print(f\"Predictions from {model_name}:\\n{model_predictions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
